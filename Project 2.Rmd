---
title: "Project 2"
author: "Autumn Hakes"
date: "2024-03-13"
output: pdf_document
---

-continuously for 1 hour
-not large data set
-3 is interaction
-not going to be able to answer these with all one model
-just stationary in it? build from there
-build up a model simple -> not as simple
-there is correlation in the data - same kid measured every minute in an hour and there's 100 different kids
-For every kid, measured every minute for an hour – 59-60 measurements – a general symmetric correlation matrix would be 60*59/2… too many to handle – don’t use general symmetric – use something else
-questions build on themselves
-1 - only use stationary, find out how well this does
-2 - throw in activities
-3 - interactions between activities and kids - effect on activity kids specific - throw that in the model - is it better than the previous two
-4 - B0 + B1Activity1 + B2Activity1:Kid1 + B3Activity:Kid2
- (B1 + B2) and (B1 + B3) ... calculate them all and draw a histogram for every activity - use names of the coefficients
-use RMSE
-stationary needs to be in the final model even if it is not significant
-validating model assumptions - it might be beneficial if you consider transformations of the response and stationary - use the log scale


```{r}
library(tidyverse)
library(readr)
library(ggplot2)
library(forecast)
library(multcomp)
library(nlme)
library(corrplot)
library(mvtnorm)
library(car)
library(GGally)
source("stdres.gls.R")


data <- read_table("BreathingZonePM.txt", show_col_types = FALSE)
data$Activity <- as.factor(data$Activity)
data$ID <- as.factor(data$ID)
```


```{r}
# Boxplot by Activity
ggplot(data, aes(x = Activity, y = Aerosol)) +
  geom_boxplot() +
  labs(title = "PM Measurements by Activity",
       x = "Activity",
       y = "PM Measurements on Vest")

# Scatterplot of Vest vs. Stationary
ggplot(data, aes(x = Stationary, y = Aerosol)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "PM Measurements on Vest vs. Stationary Monitor",
       x = "PM Measurements on Stationary Monitor",
       y = "PM Measurements on Vest")

# Scatterplot of Vest over Time Colored by Activity with Trend Lines
ggplot(data, aes(x = Minute, y = Aerosol, color = Activity)) +
  geom_point() +
  labs(title = "PM Measurements on Vest Over Time",
       x = "Minute",
       y = "PM Measurements on Vest")
```



```{r}
# Fit the linear model
lm_model <- lm(Aerosol ~ Stationary + Activity + Minute, data = data)

# Explore the residuals
residuals <- resid(lm_model)

# Organize residuals into a matrix and print it
residuals_matrix <- matrix(residuals, nrow=nrow(data), ncol = 3, byrow = TRUE)

cor(residuals_matrix)
```

There is high correlation.

## 1.

```{r}
model_ar1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar1)
AIC(model_ma1)
summary(model_ar1)
```
5760.187
5769.569

With just stationary, AR1 is lower AIC = better

```{r}
# Predict the values using the model
predicted_values <- predict(model_ar1)
observed_values <- data$Aerosol

# Calculate the RMSE
rmse <- sqrt(mean((observed_values - predicted_values)^2))
print(rmse)

# Calculate Pseudo R-squared
pseudo_r_squared <- cor(observed_values, predicted_values)^2
print(pseudo_r_squared)
```
RMSE = 10.40912: This value indicates that, on average, the model's predictions are about 10.40912 units away from the actual 'Aerosol' values. In context of the data is 10.4 lower or higher a large value?

Pseudo R-squared = 0.00313318: This value is very close to 0, suggesting that the model explains very little of the variance in the 'Aerosol' data — only about 0.31%. A low value like this one implies that the independent variables included in the model have very little predictive power concerning the dependent variable.

In summary, the RMSE is relatively high (considering the context of 'Aerosol' values), and the Pseudo R-squared is very low. Both of these suggest that the model may not be performing well in predicting the 'Aerosol' variable. It's worth considering model diagnostics and potentially looking into model improvements, such as feature engineering, model selection, or addressing any data quality issues. It could also be informative to compare this model to simpler or more complex models, or even to different types of models, to see if they can provide better predictive accuracy.

## 2. 
```{r}
model_ar2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar2)
AIC(model_ma2)

anova(model_ar1, model_ar2)
```
5680.786
5725.441

anova p-value = <.0001

Adding Activity, AR2 is the lowest so far.

```{r}
model_ar3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar3)
AIC(model_ma3)

summary(model_ar3)
```

Adding interaction between activity and kid, AR3 is the best of all of the models. AIC AR1 = 3974.764
AIC MA3 = 4732.522

```{r}
# Linear Assumption
avPlots(lm_model)


# Check independence using the decorrelated residuals
residuals <- stdres.gls(model_ar3)

# Organize residuals into a matrix and print it
residuals_matrix2 <- matrix(residuals, nrow=nrow(data), ncol = 3, byrow = TRUE)

cor(residuals_matrix2)


# Check normality using histogram of decorrelated residuals
ggplot() +
  geom_histogram(mapping = aes(x=residuals))


# Check equal variance using a fitted vs decorrelated residuals plot
ggplot()+
  geom_point(mapping = aes(x=fitted(model_ar3), y = residuals))
```

The AR models all have a lower AIC than the MA models. 

For research question 1, our model is:
```{r}
model_ar1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar1)

# Predict the values using the model
predicted_values <- predict(model_ar1)
observed_values <- data$Aerosol

# Calculate the RMSE
rmse <- sqrt(mean((observed_values - predicted_values)^2))
rmse

# Calculate Pseudo R-squared
pseudo_r_squared <- cor(observed_values, predicted_values)^2
pseudo_r_squared
```


P-value = 0, coefficient = .082 on the log scale, or e^.082

For question 2, we add in activity. The AR2 model is:
```{r}
model_ar2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar2)

# Predict the values using the model
predicted_values2 <- predict(model_ar2)
observed_values2 <- data$Aerosol

# Calculate the RMSE
rmse2 <- sqrt(mean((observed_values2 - predicted_values2)^2))
rmse2

# Calculate Pseudo R-squared
pseudo_r_squared2 <- cor(observed_values2, predicted_values2)^2
pseudo_r_squared2
```

Compare this R^2 to the R^2 with just stationary

Homework and furniture are not significant, phone, floor, games, walking, tv are significant

For question 3, we add in the interaction between activity and child (ID). The best model is AR3:
```{r}
model_ar3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar3)

# Predict the values using the model
predicted_values3 <- predict(model_ar3)
observed_values3 <- data$Aerosol

# Calculate the RMSE
rmse3 <- sqrt(mean((observed_values3 - predicted_values3)^2))
rmse3

# Calculate Pseudo R-squared
pseudo_r_squared3 <- cor(observed_values3, predicted_values3)^2
pseudo_r_squared3
```

```{r}
# Extract constrained estimates of the general correlation structure
cor_constrained <- coef(model_ar3$modelStruct$corStruct, unconstrained = FALSE)
cor_constrained

# Extract beta coefficients
coefficients <- coef(model_ar3)
coefficients

# Extract the estimate of the variance parameter sigma^2
sigma_squared <- summary(model_ar3)$sigma^2
sigma_squared
```

```{r}
getAct1 <- "Homework"
HWCoefs <- coef(model_ar3)[grepl(getAct1, names(coef(model_ar3)))]
HWCoefs[-1] <- HWCoefs[1] + HWCoefs[-1]
mean(HWCoefs)
sd(HWCoefs)
hist(HWCoefs, main = "Histogram of Homework Coefficients", xlab = "Homework Coefficients")

getAct2 <- "OnPhone"
OPCoefs <- coef(model_ar3)[grepl(getAct2, names(coef(model_ar3)))]
OPCoefs[-1] <- OPCoefs[1] + OPCoefs[-1]
mean(OPCoefs)
sd(OPCoefs)
hist(OPCoefs, main = "Histogram of On the Phone Coefficients", xlab = "On the Phone Coefficients")

getAct3 <- "PlayingOnFloor"
PFCoefs <- coef(model_ar3)[grepl(getAct3, names(coef(model_ar3)))]
PFCoefs[-1] <- PFCoefs[1] + PFCoefs[-1]
mean(PFCoefs)
sd(PFCoefs)
hist(PFCoefs, main = "Histogram of Playing on Floor Coefficients", xlab = "Playing on Floor Coefficients")

getAct4 <- "PlayingOnFurniture"
PCCoefs <- coef(model_ar3)[grepl(getAct4, names(coef(model_ar3)))]
PCCoefs[-1] <- PCCoefs[1] + PCCoefs[-1]
mean(PCCoefs)
sd(PCCoefs)
hist(PCCoefs, main = "Histogram of Playing on Furniture Coefficients", xlab = "Playing on Furniture Coefficients")

getAct5 <- "VideoGames"
VGCoefs <- coef(model_ar3)[grepl(getAct5, names(coef(model_ar3)))]
VGCoefs[-1] <- VGCoefs[1] + VGCoefs[-1]
mean(VGCoefs)
sd(VGCoefs)
hist(VGCoefs, main = "Histogram of Video Games Coefficients", xlab = "Video Games Coefficients")

getAct6 <- "Walking"
WCoefs <- coef(model_ar3)[grepl(getAct6, names(coef(model_ar3)))]
WCoefs[-1] <- WCoefs[1] + WCoefs[-1]
mean(WCoefs)
sd(WCoefs)
hist(WCoefs, main = "Histogram of Walking Coefficients", xlab = "Walking Coefficients")

getAct7 <- "WatchingTV"
TVCoefs <- coef(model_ar3)[grepl(getAct7, names(coef(model_ar3)))]
TVCoefs[-1] <- TVCoefs[1] + TVCoefs[-1]
mean(TVCoefs)
sd(TVCoefs)
hist(TVCoefs, main = "Histogram of Watching TV Coefficients", xlab = "Watching TV Coefficients")
```

Means
-0.03065063
0.1174998
0.3195713
0.07951205
0.07554739
0.0783212
0.1049647

sd's
0.882339
0.7048728
0.9520436
0.8417187
0.7179658
0.8133219
0.7708538

What activities (on average across children if child specific) lead to higher PM exposure?

"PlayingOnFloor" has the highest average coefficient value (0.3195713) and standard deviation (0.9520436). This suggests that, on average across children (if the model accounts for child-specific effects), spending time playing on the floor tends to lead to higher PM exposure 

add coefficient for activity + coefficient for activity1:kid1 + activity1:kid2 + ... + activity2kid1 + activity2kid2 +...
