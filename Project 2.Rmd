---
title: "Project 2"
author: "Autumn Hakes"
date: "2024-03-13"
output: pdf_document
---

-continuously for 1 hour
-not large data set
-3 is interaction
-not going to be able to answer these with all one model
-just stationary in it? build from there
-build up a model simple -> not as simple
-there is correlation in the data - same kid measured every minute in an hour and there's 100 different kids
-For every kid, measured every minute for an hour – 59-60 measurements – a general symmetric correlation matrix would be 60*59/2… too many to handle – don’t use general symmetric – use something else
-questions build on themselves
-1 - only use stationary, find out how well this does
-2 - throw in activities
-3 - interactions between activities and kids - effect on activity kids specific - throw that in the model - is it better than the previous two
-4 - B0 + B1Activity1 + B2Activity1:Kid1 + B3Activity:Kid2
- (B1 + B2) and (B1 + B3) ... calculate them all and draw a histogram for every activity - use names of the coefficients
-use RMSE
-stationary needs to be in the final model even if it is not significant
-validating model assumptions - it might be beneficial if you consider transformations of the response and stationary - use the log scale


```{r}
library(tidyverse)
library(readr)
library(ggplot2)
library(forecast)
library(multcomp)
library(nlme)
library(corrplot)
library(mvtnorm)
library(car)
library(GGally)
source("stdres.gls.R")


data <- read_table("BreathingZonePM.txt", show_col_types = FALSE)
data$Activity <- as.factor(data$Activity)
data$ID <- as.factor(data$ID)
```


```{r}
# Boxplot by Activity
ggplot(data, aes(x = Activity, y = Aerosol)) +
  geom_boxplot() +
  labs(title = "PM Measurements by Activity",
       x = "Activity",
       y = "PM Measurements on Vest")

# Scatterplot of Vest vs. Stationary
ggplot(data, aes(x = Stationary, y = Aerosol)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "PM Measurements on Vest vs. Stationary Monitor",
       x = "PM Measurements on Stationary Monitor",
       y = "PM Measurements on Vest")

# Scatterplot of Vest over Time Colored by Activity with Trend Lines
ggplot(data, aes(x = Minute, y = Aerosol, color = Activity)) +
  geom_point() +
  labs(title = "PM Measurements on Vest Over Time",
       x = "Minute",
       y = "PM Measurements on Vest")
```



```{r}
# Fit the linear model
lm_model <- lm(Aerosol ~ Stationary + Activity + Minute, data = data)

# Explore the residuals
residuals <- resid(lm_model)

# Organize residuals into a matrix and print it
residuals_matrix <- matrix(residuals, nrow=nrow(data), ncol = 3, byrow = TRUE)

cor(residuals_matrix)
```

There is high correlation.

```{r}
model_ar1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar1)
AIC(model_ma1)
```

With just stationary, AR1 is lower AIC = better

```{r}
model_ar2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar2)
AIC(model_ma2)
```

Adding Activity, AR2 is the lowest so far.

```{r}
model_ar3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)

model_ma3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corARMA(form = ~ Minute | ID, p = 1, q = 1),
                data = data)

AIC(model_ar3)
AIC(model_ma3)
```

Adding interaction between activity and kid, AR3 is the best of all of the models. AIC = 3974.764
MA3 = 4732.522

```{r}
# Linear Assumption
avPlots(lm_model)


# Check independence using the decorrelated residuals
residuals <- stdres.gls(model_ar3)

# Organize residuals into a matrix and print it
residuals_matrix2 <- matrix(residuals, nrow=nrow(data), ncol = 3, byrow = TRUE)

cor(residuals_matrix2)


# Check normality using histogram of decorrelated residuals
ggplot() +
  geom_histogram(mapping = aes(x=residuals))


# Check equal variance using a fitted vs decorrelated residuals plot
ggplot()+
  geom_point(mapping = aes(x=fitted(model_ar3), y = residuals))
```

The AR models all have a lower AIC than the MA models. 

For research question 1, our model is:
```{r}
model_ar1 <- gls(log(Aerosol) ~ log(Stationary),
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar1)
```

P-value = 0, coefficient = .082 on the log scale, or e^.082

For question 2, we add in activity. The AR2 model is:
```{r}
model_ar2 <- gls(log(Aerosol) ~ log(Stationary) + Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar2)
```

Compare this R^2 to the R^2 with just stationary

Homework and furniture are not significant, phone, floor, games, walking, tv are significant

For question 3, we add in the interaction between activity and child (ID). The best model is AR3:
```{r}
model_ar3 <- gls(log(Aerosol) ~ log(Stationary) + ID*Activity,
                correlation = corAR1(form = ~ Minute | ID), method = "ML", data = data)
```

```{r}
summary(model_ar3)
```

```{r}
# Extract constrained estimates of the general correlation structure
cor_constrained <- coef(model_ar3$modelStruct$corStruct, unconstrained = FALSE)
cor_constrained

# Extract beta coefficients
coefficients <- coef(model_ar3)
coefficients

# Extract the estimate of the variance parameter sigma^2
sigma_squared <- summary(model_ar3)$sigma^2
sigma_squared
```

```{r}
getAct <- "Homework"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "OnPhone"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "PlayingOnFloor"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "PlayingOnFurniture"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "VideoGames"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "Walking"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)

getAct <- "WatchingTV"
theCoefs <- coef(model_ar3)[grepl(getAct, names(coef(model_ar3)))]
theCoefs[-1] <- theCoefs[1] + theCoefs[-1]
mean(theCoefs)
hist(theCoefs)
```

-0.03065063
0.1174998
0.3195713
0.07951205
0.07554739
0.0783212
0.1049647

compare the coefficients

What activities (on average across children if child specific) lead to higher PM exposure?

"PlayingOnFloor" has the highest average coefficient value (0.3195713). This suggests that, on average across children (if the model accounts for child-specific effects), spending time playing on the floor tends to lead to higher PM exposure 

add coefficient for activity + coefficient for activity1:kid1 + activity1:kid2 + ... + activity2kid1 + activity2kid2 +...
